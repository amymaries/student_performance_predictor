{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b0aed4",
   "metadata": {},
   "source": [
    "# Student Performance Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af3220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the tools we need\n",
    "\n",
    "# Regular EDA (Exploratory Data Analysis) and plotting libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import models from skikit learn\n",
    "from sklearn.linear_model import Ridge, LinearRegression, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "\n",
    "# Model Evaluations\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213dd8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"student-mat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f5c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change \"higher\" column to binary numbers, yes=1 and no=0\n",
    "df.replace(('yes', 'no'), (1, 0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f52058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like the highest correlation to student performance(G3) is between the students grades in periods 1 & 2 (G1 & G2)\n",
    "# Dalc (weekday alcohol consumption, Walc (weekend alcohol consumption) correlate with each other, but not to grades.\n",
    "# Weekend alcohol consumption correlates with going out, but has no bearing on grades.\n",
    "# Medu and Fedu (parents education level) correlate highly with each other, with higher and slightly with Grades.\n",
    "# Study time correlates slightly with grades and also with parental education levels (Medu and Fedu).\n",
    "# The highest NEGATIVE correlation features are failures to math scores, which makes sense.\n",
    "# Absences seems to consistently correlate negatively also, though not very highly.\n",
    "#Let's eliminate a few of the features (columns) that make little sense. \n",
    "reduced_df = df[[\"Medu\", \"Fedu\", \"studytime\", \"failures\", \"higher\", \"Dalc\", \"Walc\", \"G1\", \"G2\", \"G3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dd010816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into x/y \n",
    "# X will be all columns EXCEPT target, so just drop target column\n",
    "X = reduced_df.drop(\"G3\", axis=1)\n",
    "y = reduced_df[\"G3\"]   # binary classification\n",
    "\n",
    "# Split data into train/test sets\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "93ce7351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put models in a dictionary\n",
    "models = { \"Ridge\": Ridge(),\n",
    "         \"RandomForest\": RandomForestRegressor(),\n",
    "         \"LRegression\": LinearRegression(),\n",
    "         \"ElasticNet\": ElasticNet()}\n",
    "\n",
    "# create a function to fit (train) and score models\n",
    "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Fits and evaluates given machine learning models\n",
    "    models: a dict of different Scikit-Learn machine learning models\n",
    "    X_train : training data (no labels/targets)\n",
    "    X_test: testing data (no labels)\n",
    "    y_test: testing labels\n",
    "    y_train: training labels\n",
    "    \"\"\"\n",
    "    \n",
    "    #Make a dictionary to keep model scores\n",
    "    model_scores = {}\n",
    "    \n",
    "    #Loop through models\n",
    "    for name, model in models.items():\n",
    "        # Fit the model to the data\n",
    "        model.fit(X_train, y_train)\n",
    "        # Evaluate the model and append it's score to model_scores\n",
    "        # We'll save the name of the model(KNN, LogisticRegressions, RandomForest) to the model_scores empty \n",
    "        # dictionary as the key and the score as the value\n",
    "        model_scores[name] = model.score(X_test, y_test)\n",
    "    return model_scores  # will return a dictionary\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5cd3b84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = fit_and_score(models=models, \n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_train=y_train,\n",
    "                            y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "24a81a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check MSE and MAE to calculate the error\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculating the performance of the Random Forest Regression Model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rfModel = rf.fit(X_train, y_train)\n",
    "y_pred_r = rfModel.predict(X_test)\n",
    "mae_r = mean_absolute_error(y_test, y_pred_r)\n",
    "mse_r = mean_squared_error(y_test, y_pred_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "09d00d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by trying to tune our RandomForestRegression model. \n",
    "\n",
    "# Set up two empty lists\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Create a list of different values for n_estimators  (default is 100)\n",
    "estimators = range(100, 1000, 100)\n",
    "\n",
    "# instantiate\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "# Loop through the values\n",
    "for i in estimators:\n",
    "    rfr.set_params(n_estimators=i)\n",
    "    \n",
    "    # Fit the algorithm\n",
    "    rfr.fit(X_train, y_train)\n",
    "    \n",
    "    # update the training scores list\n",
    "    train_scores.append(rfr.score(X_train, y_train))\n",
    "    \n",
    "    # update test scores list\n",
    "    test_scores.append(rfr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e2e8480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test values for max_depth\n",
    "# Set up two empty lists\n",
    "train_scores_max_depth = []\n",
    "test_scores_max_depth = []\n",
    "\n",
    "# Create a list of different values for max_depth  (default is none)\n",
    "estimators = range(1, 32)\n",
    "\n",
    "# instantiate\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "# Loop through the values\n",
    "for i in estimators:\n",
    "    rfr.set_params(max_depth=i)\n",
    "    \n",
    "    # Fit the algorithm\n",
    "    rfr.fit(X_train, y_train)\n",
    "    \n",
    "    # update the training scores list\n",
    "    train_scores_max_depth.append(rfr.score(X_train, y_train))\n",
    "    \n",
    "    # update test scores list\n",
    "    test_scores_max_depth.append(rfr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4e928223",
   "metadata": {
    "tags": [
     "{\"hide\"}"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters for our model\n",
    "param_grid = {  'max_depth': [24], 'max_features': ['auto', 'log2'], 'n_estimators': [500]}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "\n",
    "g_search = GridSearchCV(estimator = rfr, param_grid = param_grid, cv = 5, verbose = True)\n",
    "\n",
    "# Fit grid hyperparameter search model\n",
    "g_search_train_model = g_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "354ae20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_search_test_model = g_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ecb7a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the performance of the TUNED Random Forest Regression Model\n",
    "y_pred_r = g_search_train_model.predict(X_test)\n",
    "mae_r = mean_absolute_error(y_test, y_pred_r)\n",
    "mse_r = mean_squared_error(y_test, y_pred_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f034dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout, HBox, Label\n",
    "\n",
    "# Is there an event handler for these? How do we input all of the values selected into the model? \n",
    "# How can I format these so the entire description shows? HBox? VBox?\n",
    "medu_dropdown = widgets.Dropdown(options=[('None', 1), ('Elementary School', 2), ('High School', 3), ('College', 4)],\n",
    "                                value=2,\n",
    "                                )\n",
    "\n",
    "medu = HBox([Label('Mothers education level:'), medu_dropdown])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e0bb257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fedu_dropdown = widgets.Dropdown(\n",
    "            options=[('None', 1), ('Elementary School', 2), ('High School', 3), ('College', 4)],\n",
    "            value=2,\n",
    "        )\n",
    "fedu = HBox([Label('Fathers education level:'), fedu_dropdown])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "071a5311",
   "metadata": {},
   "outputs": [],
   "source": [
    "studytime = widgets.Dropdown(\n",
    "            options=[('Under two hours per week', 1), ('2-5 hours per week', 2), ('5-10 hours per week', 3), \n",
    "                     ('10+ hours per week', 4)],\n",
    "            value=2,\n",
    "        )\n",
    "study = HBox([Label('Study time per week:'), studytime])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e117b1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "failures = widgets.Dropdown(\n",
    "            options=[('Zero', 0), ('One', 1), ('Two', 2), ('Three or more', 3)],\n",
    "            value=2,\n",
    "        )\n",
    "fail = HBox([Label('Number of class failures in your past:'), failures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8adccc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "higher =  widgets.RadioButtons(\n",
    "            options=[('Yes', 1), ('No', 0)],\n",
    "            disabled=False\n",
    "        )\n",
    "high = HBox([Label('Do you plan to go to college?'), higher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2071e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dalc = widgets.Dropdown(\n",
    "            options=[(\"I don't drink alcohol on weekdays\", 1), ('One day per week', 2), ('Two days per week', 3), ('Three days per week', 4), ('Four or more days per week', 5)],\n",
    "            value=2,\n",
    "        )\n",
    "dalc = HBox([Label('Weekday alcohol consumption'), Dalc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "95e3491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Walc = widgets.Dropdown(options=[(\"No alchol\", 1), ('Low alcohol', 2), ('Some alcohol', 3), \n",
    "                                       ('A lot of alcohol', 4), ('Consistently wasted', 5)],\n",
    "            value=2,\n",
    "        )\n",
    "walc = HBox([Label('Weekend alcohol consumption'), Walc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "44c4e4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = widgets.Select(\n",
    "        options=[(\"A\", 20), ('A-', 19), ('B+', 18), ('B', 17), ('B-', 16), ('C+', 15), ('C', 14), \n",
    "                 ('C-', 13), ('D+', 12), ('D', 11), ('D-', 10), ('F', 9)],\n",
    "        # value='C',\n",
    "        # rows=10,\n",
    "        # description='First Period Grade:',\n",
    "        disabled=False\n",
    "    )\n",
    "g1 = HBox([Label('First period grade:'), G1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3763ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = widgets.Select(\n",
    "        options=[(\"A\", 20), ('A-', 19), ('B+', 18), ('B', 17), ('B-', 16), ('C+', 15), ('C', 14), \n",
    "                 ('C-', 13), ('D+', 12), ('D', 11), ('D-', 10), ('F', 9)],\n",
    "        # value='C',\n",
    "        # rows=10,\n",
    "        # description='Second Period Grade:',\n",
    "        disabled=False\n",
    "    )\n",
    "g2 = HBox([Label('Second period grade:'), G2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3d3b6589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4e01af39a5499ba89fee904f3a4b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Mothers education level:'), Dropdown(index=1, options=(('None', 1),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Layout the widget\n",
    "from ipywidgets import Button, HBox, VBox\n",
    "title_text = widgets.HTML(\"<h3 class='text-center'><font color='green'>Student Performance Predictor</font><h3>\")\n",
    "student_parameters = VBox([medu, fedu, study, fail, high, dalc, walc, g1, g2])\n",
    "student_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1053c764",
   "metadata": {},
   "source": [
    "# How much can you improve your performance with a little more studying?\n",
    "Move the slider to the number of hours you'd like to study per week and see how it affects your performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9aefc426",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-f3d72d8c669a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstudent_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmedu_dropdown\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfedu_dropdown\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudytime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfailures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigher\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDalc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWalc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# predict G3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mperformance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudent_df\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# rfr is RandomForestRegressor() but is it the tuned model?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    780\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m         \"\"\"\n\u001b[1;32m--> 782\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This RandomForestRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# how to I change this to use the G3 input by the student and the studytime input by the student from the dropdown?\n",
    "# How to create a dataframe from the values input by the students?\n",
    "\n",
    "# student_df=pd.DataFrame(data=[medu_dropdown, fedu_dropdown, studytime, failures, higher, Dalc, Walc, G1, G2])\n",
    "# predict G3\n",
    "# performance = rfr.predict(student_df) # rfr is RandomForestRegressor() but is it the tuned model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eea471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a slider so student can see how increasing study time will boost performance\n",
    "# create the widget, then create the function, then create the interaction between the function and the widget\n",
    "slider = widgets.IntSlider(\n",
    "    value=7,\n",
    "    min=0,\n",
    "    max=15,\n",
    "    step=1,\n",
    "    description='Hours per Week of Study Time:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "# plot of student performance prediction based on studytime. How do I add title and title axes?\n",
    "def adjust_performance(study_time):\n",
    "    return df.plot(x=\"performance\", y=\"studytime\");\n",
    "\n",
    "widgets.interact(adjust_performance, study_time=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8aecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar graph of student performance prediction based on medu/fedu (mothers and fathers education levels)\n",
    "model_compare = pd.DataFrame(model_scores, index=[\"accuracy\"])\n",
    "model_compare.T.plot.bar()\n",
    "plt.xticks(rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52798c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of student performance prediction based on studytime and failures\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# scatter with positive correlation\n",
    "plt.scatter(df.studytime,\n",
    "           df.G3,\n",
    "           c=\"salmon\")\n",
    "\n",
    "# Scatter plot with negative correlation\n",
    "plt.scatter(df.failures,\n",
    "           df.G3,\n",
    "           c=\"lightblue\")\n",
    "\n",
    "# Add some helpful information\n",
    "plt.title(\"Student Performance as a Result of Study Time and Failures\")\n",
    "plt.xlabel(\"Study Time\")\n",
    "plt.ylabel(\"Failures\")\n",
    "plt.legend([\"Studytime\", \"Failures\"]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
